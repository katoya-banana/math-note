元ネタはこれ  
https://algorithmsbook.com/

Agent は時刻 $t$ に「環境」から「観測」情報を取得し、「行動」を選択する。  
以下のようなものを含む、諸々の不確実性が存在する中で、目的を達成するために最適な行動を選択させたい。
* outcome uncertainty （Agent の行動が不確実である）
* model uncertainty （問題に対して用意したモデルが不確かである
* state uncertainty （環境の真の状態が不明である）
* interaction uncertainty （他の Agent の振舞いが不確実である）

意思決定を行う agent をデザインする方法にはたくさんのものがある。  
例は以下となる。

* 明示的プログラミング（全パターンに対し、選択すべき行動を組み込んでおく）
* 教師あり学習
* Optimization
* Planning
* 強化学習

元ネタの本では planning と強化学習に主に取り上げるが、教師あり学習や optimization の要素を取り込んだ手法も取り上げる。


# 確率的推論（probabilistic reasoning）

$X \perp Y$ で、$X$ と $Y$ が独立であることをさすっぽい？（用語の使い方、要チェック）   
で、条件付確率は $P(X|Y)$ と書いて「$Y$ であるときの $X$ の確率」を指す。いつも通り。  
$P(X \cap Y)$ を介することで、有名なベイズの定理
$$
P(X|Y) = \frac{P(Y|X) P(X)}{P(Y)}
$$
が導出できる。

確率変数が $X, Y, Z$ の３つの場合を例として、$P(X|Y,Z)$ をどう表現するかの例が以下。

* 全部表にして書く（明らかに、パラメータ数が増えるほど、行数は指数的に増える）
  * なんらか次元を削減できるケースがある場合は、決定木で表現すると良い場合もある
* $f \colon Y \rightarrow (\mu, \sigma)$ を用意して、正規分布 $N(\mu, \sigma)$ とする
  * とくに、$\mu = aY + b$ としたりする。
    * このとき、$\sigma$ を一定とする例があげられている。
  * $g \colon Z \rightarrow (a, b、\sigma)$ とし、正規分布 $N(aY + b, \sigma)$ とするような場合もある。

ちなみに、$X$ が取りうる値が２値の場合、正規分布の代わりに、$Y$ を引数としたシグモイドを使う場合がある。  
勝手に単調性が生じている点に注意。